[
  {
    "objectID": "token_result.html#copy-and-paste-the-token-into-your-console",
    "href": "token_result.html#copy-and-paste-the-token-into-your-console",
    "title": "Ben R Woodard's Blog",
    "section": "Copy and paste the token into your console",
    "text": "Copy and paste the token into your console"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "A simple blog about analytics and R\n          \n    \n\n                \n\n    \n    \n\n  \n\n  \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBayesian Power Analysis in R\n\n\nHow can you tell if the two groups are different, I mean different enough to make a decision?\n\n\n\n\n\nNov 16, 2025\n\n\nBen Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Adobe Analytics Segments Using R - adobeanalyticsr v0.3.0\n\n\n\nadobe analytics\n\nadobeanalyticsr\n\n\n\n\n\n\n\n\n\nFeb 28, 2022\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nAdobe Analytics API Dynamic ITP Report\n\n\n\nadobe analytics\n\nadobeanalyticsr\n\n\n\n\n\n\n\n\n\nJan 18, 2022\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate A 74 Rule Segment In Seconds\n\n\n\nadobe analytics\n\n\n\n\n\n\n\n\n\nJan 5, 2022\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nadobeanalyticsr v0.2.1 - What’s New?\n\n\n\nadobeanalyticsr\n\n\n\n\n\n\n\n\n\nJan 3, 2022\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nAnaomaly Detection adobeanalytisr\n\n\n\nadobeanalyticsr\n\n\n\n\n\n\n\n\n\nMar 2, 2021\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nNow On CRAN adobeanalyticsr\n\n\n\nR\n\n\n\n\n\n\n\n\n\nMar 1, 2021\n\n\nBen R Woodard\n\n\n\n\n\n\n\n\n\n\n\n\nHow to make a deck of cards in R\n\n\n\nR\n\n\n\n\n\n\n\n\n\nJan 24, 2021\n\n\nBen R Woodard\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-01-24-deck-of-cards/index.html",
    "href": "posts/2021-01-24-deck-of-cards/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Ben R Woodard\n        \n                    January 24, 2021\n          \n\n    \n        \n              R\nJust for the fun of it, I wanted to see how to create a complete deck of playing cards in the least amount of steps possible. Obviously, I could have just imported a premade dataset based on scraping a webpage or a csv file that someone created already but what fun would that be? So here we go!\nGoal: We need to create a deck of cards that includes 4 different suits of 13 different values, and 13 different faces.\nsuits &lt;- c('spades', 'clubs', 'diamonds', 'hearts')\n\nsuit &lt;- unlist(map(suits, rep, 13))\n\nhead(suit)\n\n[1] \"spades\" \"spades\" \"spades\" \"spades\" \"spades\" \"spades\"\nfaces &lt;- c('king', 'queen', 'jack', 'ten', 'nine', 'eight', 'seven', 'six', 'five', 'four', 'three', 'two', 'ace')\nface &lt;- rep(faces, 4)\n\nhead(face)\n\n[1] \"king\"  \"queen\" \"jack\"  \"ten\"   \"nine\"  \"eight\"\nvalue &lt;- rep(13:1, 4)\n\nhead(value)\n\n[1] 13 12 11 10  9  8\ndeck &lt;- data.frame(face, suit, value)\n\nhead(deck)\n\n   face   suit value\n1  king spades    13\n2 queen spades    12\n3  jack spades    11\n4   ten spades    10\n5  nine spades     9\n6 eight spades     8\n\ntail(deck)\n\n    face   suit value\n47   six hearts     6\n48  five hearts     5\n49  four hearts     4\n50 three hearts     3\n51   two hearts     2\n52   ace hearts     1\n\ndeck %&gt;%\n  group_by(suit) %&gt;%\n  summarise(cards = n(),\n            totalValue = sum(value))\n\n# A tibble: 4 × 3\n  suit     cards totalValue\n  &lt;chr&gt;    &lt;int&gt;      &lt;int&gt;\n1 clubs       13         91\n2 diamonds    13         91\n3 hearts      13         91\n4 spades      13         91"
  },
  {
    "objectID": "posts/2021-01-24-deck-of-cards/index.html#now-we-need-to-create-the-deal-function",
    "href": "posts/2021-01-24-deck-of-cards/index.html#now-we-need-to-create-the-deal-function",
    "title": "Ben R Woodard's Blog",
    "section": "Now we need to create the deal function",
    "text": "Now we need to create the deal function\nThe following is a simple deal function that will deal out 7 random cards (rows) from the deck and not replace those cards back into the deck during the random sample process.\n\ndeal &lt;- function(x) {\n  sample_n(deck, x, replace = F)\n}\n\ndeal(7)\n\n   face     suit value\n1   ten   spades    10\n2 queen   spades    12\n3   ten diamonds    10\n4   six diamonds     6\n5 three   spades     3\n6 queen    clubs    12\n7   six   hearts     6"
  },
  {
    "objectID": "posts/2021-01-24-deck-of-cards/index.html#lets-play-a-game-of-blackjack",
    "href": "posts/2021-01-24-deck-of-cards/index.html#lets-play-a-game-of-blackjack",
    "title": "Ben R Woodard's Blog",
    "section": "Let’s play a game of blackjack",
    "text": "Let’s play a game of blackjack\nNow that we have the deck compiled we can start playing a game. Blackjack will be a great place to start since it is fairly straight forward. The biggest problem we are going to have is dealing cards from a single deck without having it reshuffle using another function call. The remaining items in the deck must be saved as the new deck.\nThere is a simple solution to keeping the cards that were drawn from being pulled again. The ‘anti_join()’ function can help us with that.\nWe will need to remove the items from the dealers hand and save it as a list item. Then we need to deal out the 2 cards for the player. If the user wants another card then he will need to ask for a new card while supplying the dealer hand along with the user hand. It is important that these rows are not included in the deck when asked.\nLet’s edit the deal function to return all 3 elements if needed.\n\ndeal &lt;- function(x, set = NULL){\n  hand &lt;- set$myhand\n  dealerhand &lt;- set$dealerhand\n  myhand = list()\n  #remove the existing hand from the deck if it is included\n  if(!is.null(hand)) {\n    deck &lt;- deck %&gt;% anti_join(hand)\n  }\n  #remove the existing dealer's hand from the deck if it is included\n  if(!is.null(dealerhand)) {\n    deck &lt;- deck %&gt;% anti_join(dealerhand)\n  }\n  #if there is not dealer hand included then we need to get him 2 cards\n  if(is.null(dealerhand)) {\n    dealerhand &lt;- sample_n(deck, 2, replace = F)\n    #once this is done we need to remove those 2 cards from the deck\n    deck &lt;- deck %&gt;% anti_join(dealerhand)\n  }\n  #the new cards need to be drawn from the deck\n  newhand &lt;- sample_n(deck, x, replace = F)\n  #if the hand is not null then \n  if(!is.null(hand)) {\n          myhand &lt;- rbind(hand, newhand) \n        } else {\n          myhand &lt;- newhand\n          }\n  hand &lt;- list(myhand = myhand, dealerhand = dealerhand)\n  return(hand)\n  \n}\n\n#Deal the cards and get your set\nset &lt;- deal(2)\n\nJoining with `by = join_by(face, suit, value)`\n\nset$myhand\n\n   face   suit value\n1 seven hearts     7\n2  five  clubs     5\n\nset$dealerhand\n\n  face  suit value\n1  six clubs     6\n2 king clubs    13\n\n#play on if you feel lucky!\nset &lt;- deal(1, set)\n\nJoining with `by = join_by(face, suit, value)`\nJoining with `by = join_by(face, suit, value)`\n\nstr(set)\n\nList of 2\n $ myhand    :'data.frame': 3 obs. of  3 variables:\n  ..$ face : chr [1:3] \"seven\" \"five\" \"queen\"\n  ..$ suit : chr [1:3] \"hearts\" \"clubs\" \"diamonds\"\n  ..$ value: int [1:3] 7 5 12\n $ dealerhand:'data.frame': 2 obs. of  3 variables:\n  ..$ face : chr [1:2] \"six\" \"king\"\n  ..$ suit : chr [1:2] \"clubs\" \"clubs\"\n  ..$ value: int [1:2] 6 13\n\n\nNow we have the dealers hand and the players hand. This is just a start but a fun exercise for me and my 11 year old son, Garrett."
  },
  {
    "objectID": "posts/2021-02-24-now-on-cran-adobeanalyticsr/index.html",
    "href": "posts/2021-02-24-now-on-cran-adobeanalyticsr/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Now On CRAN adobeanalyticsr\n          \n    \n\n              \n          Ben R Woodard\n        \n                    March 1, 2021\n          \n\n    \n        \n              R\n          \n    \n\n  \n\n  \n  \n\n\n\n\n\nI’m super excited to announce that adobeanaltyicsr v0.1.5 is now available on CRAN! adobeanalyticsr is an R client for the new ‘Adobe Analytics’ API 2.0 and had a lot of great features that I believe will help data analysts do their jobs better.\n\nThe new adobeanalyticsr package was an open source project that started when Tim Wilson began exploring functions that would pull data using the new API 2.0. This API has already been making waves in the analytics industry since it’s introduction via the Analysis Workspace user interface a few years back.\nI believe it is critical to thank Randy for the work he put in to creating and maintaining RSiteCatalyst. His development work on the old Adobe Analytics R package quite literally changed the way I did my job and the questions I could ask. I truly hope that adobeanalyticsr can continue the level of excellence that Randy instilled in RSiteCatalyst.\nHere are a few of the features the new R package for Adobe Anaytics affords us as analysts over the old API:\n\nUp to 20 dimensions at a time.\n\nThe old API 1.4 had a limit of 4\nThe API 2.0 doesn’t have any restrictions but the package does. This limitation is only temporary while we develop the package.\n\nFaster API calls.\n\nThe old API used a queue process.\nThe new API has no queue but needs recursive data requests to pull breakdown reports.\n\nFuture functionality\n\nThe old API has not been developed in quite a while\nThe new API is getting a lot of focus since it is the backbone of Analysis Workspace.\n\n\nThose three distinctions are just a few of the many benefits of using the new api. Now with the package being included in CRAN, everyone can easily begin using the new powerful API.\ninstall.packages('adobeanalyticsr')\nlibrary(adobeanalyticsr)\nWhile this is a great milestone that has been in the works for about a year and a half, it is just the beginning. Development work has already begun on the next itteration of the package. We are looking for more community feedback and would love to hear your thoughts on improvements and enhancements to the package. Checkout AdobeAnalyticsR.com for more information and a link to the github repo where you can submit issues and submit enhancments."
  },
  {
    "objectID": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html",
    "href": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Ben R Woodard\n        \n                    January 18, 2022\n          \n\n    \n        \n              adobe analytics\n              adobeanalyticsr\n#Setup chunk options\nknitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE,\n                      eval = FALSE)\nWarning: Measuring ITP impact is a classic example of attempting to measure a “moving target”. The example below uses segment definitions that were effective at showing the impact of ITP on traffic as of late 2021. This is for demonstration purposes only.\n#install.packages('adobeanalyticsr')\n# Download packages needed for the report\nlibrary(adobeanalyticsr) #pulls data from Adobe Analytics\nlibrary(tidyverse) #used in data wrangling\nlibrary(scales) #used for visually cleaner numbers\nlibrary(lubridate) #makes working with dates much easier\n# library(itpreportr) #internal r package\n\naw_auth('s2s')"
  },
  {
    "objectID": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#setup-for-the-itp-impact-report",
    "href": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#setup-for-the-itp-impact-report",
    "title": "Ben R Woodard's Blog",
    "section": "Setup for the ITP impact report",
    "text": "Setup for the ITP impact report\nThe first setup step is identifying the report suite you are going to be using for the report. This can be as easily as looking in the admin for Adobe Analytics or running the aw_get_reportsuites() function in adobeanalyticsr. Either way, this step should be fairly simple.\nThe second step is usually done through training and reviews but when using code we can generate visuals that more consistently aligned with our expectations. While visuals are still customized for each report, this type of code based deliverable enables us to include visualization best practices into all of our reports and presentations.\nFinally, the last step of our setup process is creating the segments and calculated metrics. Historically, we have needed to go into a report suite and create these elements. There were problems with consistent naming conventions and other user errors due to having so many ‘touch points’ in that process. By using the API we have been able to streamline this step in the setup process. It is now a single function that first checks for existing segments with the same name in the account and then builds them if they do not exist.\nThe power of this report is in the ability to automate the segment creation process and then pull data according to each segment without ever having to log into the user interface. Since the segment definitions use basic dimensions and metrics, there is no need to customize these dimensions across report suite.\n\n#Define the ReportSuite to be used\nrsid &lt;- 'lumalucaslidemo'\n\n## Get the base ggplot theme design attributes\ntt &lt;- tim_themes()\n\n## Get the Segment ID's\n### create the segments and calculated metric\nsegids &lt;- create_itp_segments()\n### assign the ids needed to call the appropriate data\nbest_seg &lt;- segids$bestseg\nworst_seg &lt;- segids$worstseg\nreturn_seg &lt;- segids$returnseg\nreturn_cm &lt;- segids$returncm"
  },
  {
    "objectID": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#visualize-the-impact",
    "href": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#visualize-the-impact",
    "title": "Ben R Woodard's Blog",
    "section": "Visualize the Impact",
    "text": "Visualize the Impact\nNow that we have the setup done, we can get right into the visualization part. This has been a hot topic among my peers on the best way to present the ITP Impact. The following visuals are adjusted a little (or a lot) with every client presentation but they give us a solid start to communicating the impact of ITP on their analytics.\n\n90 Day View\nThe first visual shows the distribution of the ‘Best Case’ Traffic estimate vs the ‘Worst Case’ Traffic segments over the last 90 days.\n\nFirst we need to pull the 3 different data sets using the segments.\n\n\nWe add one column to the results, ‘type’, to help make the distinction between data sets.\n\n\n#pull the all traffic 90 day data\nall.ninetydays &lt;- aw_freeform_table(rsid = rsid,\n                                    date_range = c(Sys.Date()-91, Sys.Date()-1),\n                                    dimensions = 'daterangeday',\n                                    metrics = 'visits') %&gt;%\n                    mutate(type = 'all.visits')\n#pull the best case segment traffic 90 day data\nbest.ninetydays &lt;- aw_freeform_table(rsid = rsid, \n                                    date_range = c(Sys.Date()-91, Sys.Date()-1),\n                                    dimensions = 'daterangeday',\n                                    metrics = c('visits'),\n                                    segmentId = best_seg) %&gt;%\n                    mutate(type = 'best.case')\n#pull the worst case segment traffic 90 day data\nworst.ninetydays &lt;- aw_freeform_table(rsid = rsid,\n                                      date_range = c(Sys.Date()-91, Sys.Date()-1),\n                                      dimensions = 'daterangeday',\n                                      metrics = c('visits'),\n                                      segmentId = worst_seg) %&gt;%\n                    mutate(type = 'worst.case')\n\n\nNow we need to combine the data.\n\n\nDue to the fact that all the columns are the same we can use the base rbind function.\n\n\n#row bind the data together\nninetydays &lt;- rbind(best.ninetydays, worst.ninetydays, all.ninetydays)\n\n\nBefore creating the visual we need the averages and annotations.\n\n\nThis step includes 2 summary data points to help provide additional information on the chart\n\n\n#transform the data a bit to present percentages\navg_traffic &lt;- ninetydays %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  mutate(avg_worst = round(mean(worstcase_prop), digits = 2),\n         avg_best = round(mean(bestcase_prop), digits = 2)) %&gt;%\n  distinct(avg_worst, avg_best)\n#define where the annotations should appear on the chart\nannotation_location &lt;- ninetydays %&gt;%\n  filter(daterangeday == max(ninetydays$daterangeday)-30) %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  select(daterangeday, bestcase_prop, worstcase_prop)\n\n\nFinally we create the visual.\n\n\nThis can look intimidating at first but visual customization is a big reason for doing the ITP Impact Report in R\nWe usually only have to adjust the 2 items commented below in the code. (‘#’ signifies a comment)\n\n\n#create the visualization using the data\nninetydays %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  mutate(avg_worst = round(mean(worstcase_prop), digits = 2),\n         avg_best = round(mean(bestcase_prop), digits = 2)) %&gt;%\n  select(daterangeday,bestcase_prop, worstcase_prop, avg_worst, avg_best) %&gt;%\n  pivot_longer(cols = 2:3) %&gt;%\n  ggplot(aes(daterangeday, value, color = name)) + \n  geom_line() +\n  scale_color_manual(values = c('#F58220', '#009CAB')) +\n  scale_y_continuous(labels = scales::percent, limits = c(0, 1) ) +\n  annotate('text', \n           label= glue::glue('Worst Case Avg. \\n {scales::percent(avg_traffic$avg_worst)}'),  \n           x = max(ninetydays$daterangeday)-10, \n           y = annotation_location$worstcase_prop + .29, #adjust the distance from the 'worst' line on the graph\n           color = '#009CAB', \n           fill = 'white') +\n  annotate('text', \n           label= glue::glue('Best Case Avg. \\n {scales::percent(avg_traffic$avg_best)}'),  \n           x = max(ninetydays$daterangeday)-10, \n           y = annotation_location$bestcase_prop + .15, #adjust the distance from the 'best' line on the graph\n           color = '#F58220', \n           fill = 'white') +\n  tt$theme_lines +\n  theme(legend.position = 'none', title = element_text(vjust = 1), \n        plot.title = element_text(face = 'plain', hjust = 0.0), \n        plot.subtitle = element_text(color = '#333333', vjust =5), \n        plot.caption = element_text(color = '#888888', face = 'italic', size = 8) ) +\n  labs(title = \"Estimated Best and Worst Case ITP Impacted Traffic\", \n       subtitle = '90 Day Traffic Trend and Average', \n       caption = glue::glue('Data Source: reportsuite *rsid*'))"
  },
  {
    "objectID": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#larger-trend-by-month",
    "href": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#larger-trend-by-month",
    "title": "Ben R Woodard's Blog",
    "section": "Larger Trend by Month",
    "text": "Larger Trend by Month\nThis next visual gives a larger look-back window and summarizes it by month as opposed to day. It is intended to help the analyst answer the following questions:\n\nHas traffic been steady, increasing, or decreasing?\nDo we see seasonality trends?\n\nIt also should inform whether or not we will expect changes going forward for volume of Best and Worst Case visits.\n\nPull the data\n\nBecause we want the best look-back window possible we start by defining how many days March 1, 2020 was from today. This number will be used in the function argument date_range to make sure we include much of 2020 without having to do much additional math. We could add the data in the character form, ‘2020-04-01’, but then we would have to define today’s date in the same character format in order for the c() function to send in the date range correctly. It’s easier to define the days since today and then just subtract it from today’s date.\n\n#determine the number of days to subtract from today\ndayssince200401 &lt;- as.numeric(Sys.Date()-1 - as.Date('2020-04-01'))\n#pull the data\nall.12months &lt;- aw_freeform_table(rsid = rsid,\n                                    date_range = c(Sys.Date()-dayssince200401, Sys.Date()-1),\n                                    dimensions = 'daterangemonth',\n                                    metrics = c('visits')) %&gt;%\n                    mutate(type = 'all.visits')\nbest.12months &lt;- aw_freeform_table(rsid = rsid, \n                                    date_range = c(Sys.Date()-dayssince200401, Sys.Date()-1),\n                                    dimensions = 'daterangemonth',\n                                    metrics = c('visits'),\n                                    segmentId = best_seg) %&gt;%\n                    mutate(type = 'best.case')\nworst.12months &lt;- aw_freeform_table(rsid = rsid,\n                                      date_range = c(Sys.Date()-dayssince200401, Sys.Date()-1),\n                                      dimensions = 'daterangemonth',\n                                      metrics = c('visits'),\n                                      segmentId = worst_seg) %&gt;%\n                    mutate(type = 'worst.case')\n\n\nBind the rows\n\n\n## bind the data sets together\ntwelvemonths &lt;- rbind(best.12months, worst.12months, all.12months)\n\n\nGet additional data points\n\n\nAs in the previous section, we need to do a little data wrangling to get additional points of information.\n\n\n# Transform the daterangemonth column to date, just in case.\ntwelvemonths &lt;- twelvemonths %&gt;%\n  mutate(date = lubridate::my(daterangemonth)) \n# Define how man months we are looking at\nmonthscount &lt;- length(unique(twelvemonths$daterangemonth))\n# Get the averages in traffic\navg_traffic &lt;- twelvemonths %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  mutate(avg_worst = round(mean(worstcase_prop), digits = 2),\n         avg_best = round(mean(bestcase_prop), digits = 2)) %&gt;%\n  distinct(avg_worst, avg_best)\n# Define the annotations needed for the visual\nannotation_location &lt;- twelvemonths %&gt;%\n  filter(date == max(floor_date(twelvemonths$date))) %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  select(date, bestcase_prop, worstcase_prop)\n\n\nVisualize the longer trended data\n\n\ntwelvemonths %&gt;%\n  pivot_wider(names_from = type, values_from = visits) %&gt;%\n  mutate(bestcase_prop = round(best.case/all.visits, digits = 2),\n         worstcase_prop = round(worst.case/all.visits, digits = 2)) %&gt;%\n  mutate(avg_worst = round(mean(worstcase_prop), digits = 2),\n         avg_best = round(mean(bestcase_prop), digits = 2)) %&gt;%\n  select(date, bestcase_prop, worstcase_prop, avg_worst, avg_best) %&gt;%\n  pivot_longer(cols = 2:3) %&gt;%\n  ggplot(aes(date, value, color = name)) + \n  geom_line() +\n  scale_color_manual(values = c('#F58220', '#009CAB')) +\n  annotate('text', \n           label= glue::glue('Worst Case'),  \n           x = max(twelvemonths$date)-30, \n           y = annotation_location$worstcase_prop + .07, \n           color = '#009CAB', \n           fill = 'white') +\n  annotate('text', \n           label= glue::glue('Best Case'),  \n           x = max(twelvemonths$date)-30, \n           y = annotation_location$bestcase_prop + .07, \n           color = '#F58220', \n           fill = 'white') +\n  tt$theme_lines +\n  theme(legend.position = 'none', \n        title = element_text(vjust = 1), \n        plot.title = element_text(face = 'plain', hjust = 0.0), \n        plot.subtitle = element_text(color = '#333333', vjust =5), \n        plot.caption = element_text(color = '#888888', face = 'italic', size = 8)) +\n  geom_vline(xintercept = as.Date('2020-11-04'), #this mark the vertical line when ITP was launched\n             color = 'light grey', linetype = 3) +\n  annotate('text', \n           label = 'Nov 5 Apple ITP', \n           angle = 90, x = as.Date('2020-10-30'), \n           y = .75, color = 'light grey') +\n  scale_y_continuous(labels = percent, limits = c(0, 1) ) +\n  scale_x_date(breaks = '2 months', date_labels = \"%b '%y\") +\n  labs(title = \"Apple OS Traffic Has Been Increasing\", #change the title\n       subtitle = glue::glue('{monthscount} Month ITP At Risk Traffic'), #change the subtitle\n       caption = glue::glue('Data Source: reportsuite *rsid*'))"
  },
  {
    "objectID": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#example-of-itp-analytics-impact",
    "href": "posts/2022-01-18-adobe-analytics-api-dynamic-itp-report/index.html#example-of-itp-analytics-impact",
    "title": "Ben R Woodard's Blog",
    "section": "Example of ITP Analytics Impact",
    "text": "Example of ITP Analytics Impact\nThis final visual takes the percentage of returning after 7 day visits before and after the date ITP was implemented on November 5th, 2020. It is used to illustrate of one of the impacts of ITP on reporting.\n\nPull the data\n\n\ndr = c(as.Date('2020-05-01'), Sys.Date()-1)\nall.prev12 &lt;- aw_freeform_table(rsid = rsid,\n                                date_range = dr,\n                                dimensions = 'daterangemonth',\n                                metrics = c('visits', return_cm),\n                                prettynames = F) %&gt;%\n                    mutate(type = 'all.visits')  %&gt;%\n  dplyr::rename(visits7days = 3)\n\nbest.prev12 &lt;- aw_freeform_table(rsid = rsid, \n                                    date_range = dr,\n                                    dimensions = 'daterangemonth',\n                                    metrics = c('visits', return_cm),\n                                    segmentId = best_seg,\n                                  prettynames = F) %&gt;%\n  mutate(type = 'best.case') %&gt;% \n  dplyr::rename(visits7days = 3)\n\nworst.prev12 &lt;- aw_freeform_table(rsid = rsid,\n                                      date_range = dr,\n                                      dimensions = 'daterangemonth',\n                                      metrics = c('visits', return_cm),\n                                      segmentId = worst_seg,\n                                   prettynames = F) %&gt;%\n  mutate(type = 'worst.case') %&gt;% \n  dplyr::rename(visits7days = 3)\n\n\nBind the data\n\n\nprev12 &lt;- rbind(best.prev12, worst.prev12, all.prev12)\n\n\nTransform the data\n\n\nThe biggest change in this step over the previous transformation steps is categorizing the date as being ‘after’ or ‘before’ the ITP changes.\n\n\nprev12 &lt;- prev12 %&gt;%\n  mutate(date = lubridate::my(daterangemonth)) \n\navg7dayreturns &lt;- prev12 %&gt;%\n  mutate(sinceitp = if_else(date &gt; as.Date('2020-10-31'), 'After', 'Before'))\n\n\nVisualize the data\n\n\navg7dayreturns %&gt;%\n  mutate(type = case_when(type == 'all.visits' ~ 'All Visits', \n                          type == 'best.case' ~ 'Recent Apple OS',\n                          type == 'worst.case' ~ 'All Apple OS')) %&gt;%\n  group_by(sinceitp, type) %&gt;%\n  summarise(avg7dayreturns = sum(visits7days, na.rm = T)/sum(visits, na.rm = T)) %&gt;%\n  mutate(type = factor(type, levels = c('All Visits', 'All Apple OS', 'Recent Apple OS'))) %&gt;%\n  mutate(sinceitp = factor(sinceitp, levels = c('Before', 'After'))) %&gt;%\n  filter(type != 'Recent Apple OS') %&gt;%\n  ggplot(aes(type, avg7dayreturns, fill = sinceitp)) + \n  geom_bar(stat = 'identity', position = position_dodge(width = .75 ), width = .7) +\n  geom_text(aes(label = percent(avg7dayreturns, accuracy = 1)), position = position_dodge(width = .75), vjust =1.3, color = '#efefef', size = 7) +\n  tt$theme_bar_nolines +\n  scale_y_continuous(expand = c(0, 0)) +\n  theme(axis.text.y = element_blank(), legend.position = c(1,1.1), legend.justification = c(1,1),\n              legend.background = element_blank(), plot.title = element_text(hjust = 0, vjust = -2),\n        plot.caption = element_text(face = 'italic', size = 6)) +\n  scale_fill_manual(values = c('#F58220', '#009CAB')) +\n  labs(title = \"Average Post 7 Day Return Traffic Is Decreasing\", \n       subtitle = 'Before and After Apple Implemented ITP Changes - Average Return Traffic',\n       caption = glue::glue('ITP Change: Nov. 5, 2020 \\n Data Source: reportsuite *rsid*'))\n\nUsing this framework creates the images but most importantly, enables the analyst to quickly add in-line commentary and recommendations to the final deliverable."
  },
  {
    "objectID": "posts/2021-03-02-anaomaly-detection-adobe-api-2-0-adobeanalytisr/index.html",
    "href": "posts/2021-03-02-anaomaly-detection-adobe-api-2-0-adobeanalytisr/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Anaomaly Detection adobeanalytisr\n          \n    \n\n              \n          Ben R Woodard\n        \n                    March 2, 2021\n          \n\n    \n        \n              adobeanalyticsr\n          \n    \n\n  \n\n  \n    \n    \n  \n  \n\n\n\n\n\nWhen I first started working with the new Adobe Analytics API 2.0 I wanted to tap into the powerful anomaly detection that was built into Analysis Workspace. According to Adobe “Anomaly Detection provides a statistical method to determine how a given metric has changed in relation to previous data.” \nThe hope was always that the Anomaly Detection would allow analysts to separate “true signals” from “noise” but that’s been pretty difficult in the Analysis Workspace UI. It has definitly helped ‘identify potential factors that contributed to those signals or anomalies’ but it has fallen short in actually providing the final solution. That’s because anomalies are complex and require context to prove whether the event can be repeated or should just be explained.\nThe hope of anomaly detection has always the same. Adobe’s documentation expresses it very well.\n\n…it lets you identify which statistical fluctuations matter and which don’t. You can then identify the root cause of a true anomaly. Furthermore, you can get reliable metric (KPI) forecasts.\n\nUnfortunately the reality is that using this tool of statistical analysis can prove to be a lot of wasted time and effort. With that being said, Adobe’s anomaly detection does provide a very powerful opportunity if used correctly.\nThe current application of Analysis Workspace’s anomaly detection algorithm includes\n\nSupport for hourly, weekly, and monthly granularity, in addition to the existing daily granularity.\nAwareness of seasonality (such as “Black Friday”) and holidays.\n\n\nSo what does this look like in adobeanalyticsr?\nThe new adobeanaltyicsr function for anomaly detection, aw_anomaly_report(), is designed to facilitate the principle of “speed to analysis” while fostering better reporting opportunities.\nThe default function call will return a basic data frame of 7 different columns.\nIf you request more than one metric it will return a row for each metrica at the granularity level you requested in the function.\nFor instance, the following function will return this:\naw_anomaly_report(date_range = c(\"2020-12-01\", \"2021-03-01\"),\n                  metrics = c('visits','visitors'))\n\ngt::gt(head(aw_anomaly_report(date_range = c(\"2024-12-01\", \"2024-12-31\"),\n                  metrics = c('visits','visitors'),\n                  rsid = 'lumalucaslidemo'), 10))\n\nNotice that each row includes the data, expected, upper bound, and lower bounds calculated for you already. It also includes whether or not the data crossed one of those bounds and was determined to be an anomaly.\nFor those looking to get to the ‘raw’ data, this should be just what you need to get going. But there are many times that all you are wanting to do is visualize the data or just show the dates that an anomaly was detected. This was my main use case so I created an argument that will help you quickly view the results.\nAdding the argument quickView = TRUE to the function call will return a list of 3 items. It will also split these results by the different metrics that were requested, if there are more than 1 in the request.\nThe following example shows the same function call as above but it includes the quickView = TRUE argument. The list includes:\n\nData = The raw data just like in the default function but split up by metric if you have requested more than one.\nAnoms = The filtered view of the data showing only those rows (by metric) where ‘anomalyDetection = TRUE’.\nViz = A line graph produced using ggplot which includes the error bar, points on the timeline where an anomay was detected, and finally the data shown in a line expanding over the period requested in the date range.\n\n\ndf &lt;- aw_anomaly_report(date_range = c(\"2020-12-01\", \"2021-03-01\"),\n                  metrics = c('visits','visitors'),\n                  quickView = TRUE, \n                  rsid = 'lumalucaslidemo')\ndf[[1]]$data\ndf[[1]]$anom\n\n\n\ndf[[2]]$data\ndf[[2]]$anoms\n\n\nFor more on Anomaly Detection in Analysis Workspace check out this video.\n\n\nI’m always looking for new ways to serve up the anomaly detection data. If you have an idea, make sure to submit an issue for me to work on with you."
  },
  {
    "objectID": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html",
    "href": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Ben R Woodard\n        \n                    February 28, 2022\n          \n\n    \n        \n              adobe analytics\n              adobeanalyticsr\nAdobe Analytics has built a great UI for building segments which lowers the entry point for analysts to have the ability to create meaningful segments quickly. The segment builder user interface (UI) contains drag and drop functionality that encourages a better understanding of what makes a basic and complex segments.\nSince all good data analysis includes a repeatable process, it is important to have a way to code segments into your analysis workflow. The new set of segment building functions in the newest version of adobeanalyticsr enables that very thing.\nThankfully, everything the UI does is built on “Adobe Analytics API v2.0”. The goal of this article is to show a basic example to help get get you started.\nLet’s get going!\nIf needed, install the package. The latest version (v0.3.0) includes the segment building functionality I am presenting here.\n#install.packages('adobeanalyticsr')\nOnce the package is installed in your library it is essential to load the package into your working session by using the library() function.\nlibrary(adobeanalyticsr)\nThe Adobe Analytics API v2.0 has two ways to authenticate and adobeanalyticsr supports both. Make sure to check out the aw_auth() function (?aw_auth) for more information on which is the best for you. In this case I’m using the JWT authentication. This simply means I’ve downloaded the service account JSON file and the private.key file from my project in the developer.adobe.io console and referenced the file path in the .Renviron using the two variables, AW_AUTH_FILE and AW_PRIVATE_KEY.\n# Authenticate\naw_auth('s2s')\nNext, I will need to define the report suite that I am going to be using as the validation for our new segment. While segments can be used in multiple report suites across your Adobe Analytics account, it is important to use the appropriate base report suite for validation purposes. (Note: You do have to have access to this report suite via your authentication.)\nrsid &lt;- 'lumalucaslidemo'\nBuilding segments in Adobe Analytics consists of 2 main elements Rules and Containers. Grasping these 2 basic concepts will go a long way in the ability to integrate segment building into your analysis workflow."
  },
  {
    "objectID": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#define-the-rules",
    "href": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#define-the-rules",
    "title": "Ben R Woodard's Blog",
    "section": "Define the Rule(s)",
    "text": "Define the Rule(s)\nRules are made up of 3 main elements: subject (dimension/metric), verb, and object.\n\n\n\nRule\n\n\n\nSubject\nThe subject is what is main part of the rule. It has to be defined as either a “metric” or a “dimension”. You can identify the metrics by downloading them using the aw_get_metrics() function and dimensions can be downloaded by using the aw_get_dimensions() function.\n\n\nVerbs\nEvery rule includes a linking verb which relates the object back to the subject. There are 32 verb options in the segment documentation but number list verbs are a little unclear so there are 2 additional verbs listed as options in the package data documentation (?seg_verbs).\n\nDT::datatable(seg_verbs, \n              extensions = c('FixedColumns',\"FixedHeader\"),\n              options = list(scrollX = F, \n                             paging=T,\n                             fixedHeader=T))\n\n\n\nBuilding the rule\nEach rule of a segment must be defined separately. This is similar to the way you build rules in the UI. The following example is a rule that says the dimension “page” must equal “Home” to be included into the segment.\n\nrule1 &lt;- seg_rule(dimension = 'page', \n                  verb = 'streq',\n                  object = 'home')\n\nThe rule1 object is a list item that will be turned turned a JSON string to be used in the API call to build or validate the function.\nIn this example I want to add another rule to help define the limitation of our segment. The next rule limits the visits to be on January 5, 2025.\n\nrule2 &lt;- seg_rule(dimension = 'daterangeday',\n                  verb = 'eq',\n                  object = '2025-01-05')\n\nFinally, we want to add an additional rule to be used as an optional qualifier for visits to be included in this segment. For some reason we want to also include all visits that were on a mobile device. The rule says that the dimension “mobiledevicetype” value must ‘equal’ “Mobile Phone” to be included.\n\nrule3 &lt;- seg_rule(dimension = 'mobiledevicetype',\n                  verb = 'eq',\n                  object = 2163986270)\n\n\nNote: There are some quirks to the API that I am still trying to figure out. One of these is represented in this example. While the UI is clearly a list of mobile device types such as “Mobile Phone”, the API is actually needing a number. That is why I am using the numeric “eq” verb with a dimension. I only include this example to point out the fact that this process of building segments using code is valuable but there is a learning curve. Most of the time you will not have any problems at all but there are some circumstances that may require you to do a bit of research to get it right using the API."
  },
  {
    "objectID": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#create-the-container",
    "href": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#create-the-container",
    "title": "Ben R Woodard's Blog",
    "section": "Create the Container",
    "text": "Create the Container\nEvery segment has at least one container. Adding an additional container to the main container is only needed if you are using a different “conjunction” between then. Here I am creating a “visit” context container using “rule1” and “rule2” and using the conjunction “and”. This will result in a segment that includes visits where both rules are true.\n\ncontainer1 &lt;- seg_con(context = 'visits',\n                      conjunction = 'and',\n                      rules = list(rule1, rule2))"
  },
  {
    "objectID": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#build-the-segment",
    "href": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#build-the-segment",
    "title": "Ben R Woodard's Blog",
    "section": "Build the Segment",
    "text": "Build the Segment\nNow that we have the rules and containers defined we need to build the segment using the seg_build() function. By default, this will return a JSON string that can then be validated using the seg_val() function but you are able to change the argument “create_seg” to TRUE and it will create the segment in the UI and return the segment id which can then be used in your other API calls.\nIn the following example the segment name is “Home Page visits” and the description is “All visits that include a page named ‘Home’”. I am using the “containers” argument because we have at least one container to be included in our segment. If we were just using rules then we would use the “rules” argument.\n\nbuilt &lt;- seg_build(name = \"Home Page visits\",\n                   description = \"All visits that include a page named 'Home'\",\n                   containers = list(container1, rule3),\n                   context = 'visits',\n                   conjunction = \"or\",\n                   create_seg = FALSE, \n                   rsid = rsid)\n\nSince the argument create_seg() is set to FALSE, the response of the function is a json string. As you can see, segment definitions can become quite complex to debug but going through each step of the process can help you quickly identify any issues or areas you can improve on. But now you also have a clear understanding of the definition and can easily include this as part of your analysis documentation. This analysis artifact can then be used by your future self or the next analyst.\nFinally, let’s make sure this segment will validate in the report suite. It is important to note that the validation function uses the segment validation endpoint which doesn’t confirm the segment definition is returning any results, it simply validates that the segment elements are able to be used in the way you have compiled them. For instance, if you were to use “mobiledevice” instead of “mobiledevicetype” then the result of seg_val(built) would return an error stating the dimension was not able to be found.\nIf the segment validates it should look like this:\n\nseg_val(built)"
  },
  {
    "objectID": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#conclusion",
    "href": "posts/2022-02-28-build-adobe-analytics-segments-using-r-adobeanalyticsr-v0-3-0/index.html#conclusion",
    "title": "Ben R Woodard's Blog",
    "section": "Conclusion",
    "text": "Conclusion\nWe have already been using this in our analysis and data science workflows and it has proven to be a big help. In one scenario, I had to create 13 different complex segments based on the defined segments we wanted to isolate in our analysis. After creating them all in R I presented the initial findings to the team who quickly noticed I was missing an exclusion rule that should have been included on all 13 different segments. Normally the process would have been a huge headache but thankfully, I had coded all the segments and adding one simple exclusion rule to each one was quick. In addition, I was able to move forward with more confidence in my segments because using code eliminates much of the errors that happend due to multiple touch points in generating an analysis."
  },
  {
    "objectID": "posts/2022-01-03-adobeanalyticsr-v0-2-1-what-s-new/index.html",
    "href": "posts/2022-01-03-adobeanalyticsr-v0-2-1-what-s-new/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "adobeanalyticsr v0.2.1 - What’s New?\n          \n    \n\n              \n          Ben R Woodard\n        \n                    January 3, 2022\n          \n\n    \n        \n              adobeanalyticsr\n          \n    \n\n  \n\n  \n  \n\n\n\n\n\nI’m happy to announce there is a new version of adobeanalyticsr on CRAN. The new version brings some pretty big updates with it. Here are the top 4 that I feel are the biggest changes and improvements.\n\n1. JWT Authentication Support\nThis has been a long time coming. I have to admit that I have been working on getting JWT authentication working since the first version of the R package was published but just couldn’t get it done. Early last year after the first version was published to CRAN I had several conversations with analysts who, unfortunately, could not use the R package simply because it only used the OAuth authentication process.\nWell that all changes with adobeanalyticsr v0.2.1 thanks to the work of Charlie Gallagher. A few months back he submitted the package’s first official pull request from the community and it was JWT authentication.\nThe old ‘aw_token()’ function still works but has been deprecated due to the need to include 2 options for authentication versus just one. The goal was to not break existing workflows but enable future workflows to switch between authentication options as seamlessly as possible. (more on this below)\nI’ve been using the new auth functions in my workflow since early November of last year and it is a great improvement, especially if you have the need to switch between authentication types.\n\n\n2. New Auth Functions\nThe new update brings a change to the authentication process with some new functions:\n  aw_auth()\n  aw_auth_with()\n  aw_auth_name()\n  aw_auth_path()\nThere are a few options for setting session options that are going to be really helpful when creating automated workflows. There is a two step process that lets you set a session option for which authentication type you want to use. By using the function aw_auth_with('jwt') you are setting your preferred method as jwt (alternatively aw_auth_with('oauth') sets the preferred method as oauth) and then you can use the function aw_auth() to authenticate, without having to define anything else.\nIn addition, you can also just include the value jwt or oauth in the aw_auth() function call like so: aw_auth('jwt'). I usually end up doing that since I’m mainly working on analysis reports and not developing work streams that require more modular development.\n\naw_auth('s2s')\n# or\naw_auth_with('s2s')\naw_auth()\n\nThere are several big differences between these two types of authentication, more to come soon on what those are.\n\n\n3. Deprecating aw_token()\nSince we have a new function that handles the authentication process, we have added an end of life notice for the aw_token() function with a life-cycle warning.\nThis function still exists but has been superseded by aw_auth(). While it does not require a change right now, I would encourage you to start changing over to the new authentication functions, even if you are still using OAuth. We have added a live-cycle warning to help remind users to do so.\n\n\n\n‘aw_token()’ lifecycle warning\n\n\n\n\n4. New Segment Table Function\nWe have also added a new function which returns one or multiple segments as dimensions and their corresponding metrics in each row. The new function is aw_segment_table(). It mimics the output of aw_freeform_table() but doesn’t support dimension breakdowns at this time. It does however have a segment filter you can add so you are able to segment your segment report by another segment.\nI think I get excited about most of these new features because of it creates an efficiency that can’t be created outside of code.\nHere is a sample process you can use to run the report.\n\nGet the Segments\n\n\n#pull up to 1,000 segments from adobe\nsegs &lt;- aw_get_segments(limit = 1000, rsids = Sys.getenv('AW_REPORTSUITE_ID'))\n\n\nGather the Segment IDs\n\nThis is a very simple example but I’m wanting to compare ‘Mobile’ and ‘Desktop’ visitors to the site. To get the Id for these, I’m simply using the base grepl() function to pull back the Segment IDs.\n\nmobilevisitors &lt;- segs$id[grepl('Mobile Visitors', segs$name)]\ndesktopvisitors &lt;- segs$id[grepl('Desktop Visitors', segs$name)]\n\nsegments &lt;- c(mobilevisitors, desktopvisitors)\n\n\nPull the Segment Table\n\nNow I can use those 2 segments to pull my data for each segment in a table.\n\ndf &lt;- aw_segment_table(date_range = c('2021-11-01', '2021-12-31'),\n                       segmentIds = segments,\n                       metrics = c('visitors', 'visits', 'pageviews'))\n\nI’ll definitely be writing more on the different ways you can utilize this functions but even the most basic use cases have already proven to be a huge benefit to my analysis workflows.\nIf you have any questions or suggestions I would love to hear them. Let me know in the comments or via #MeasureSlack."
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Ben R Woodard\n        \n                    January 5, 2022\n          \n\n    \n        \n              adobe analytics\nHere is the situation we find ourselves in. Our client, a small company in the North West United States named Apple, has asked us to identify all visits that have used a menu-item-name as a value in the search feature on the site. They want us to do a segmentation analysis between these users and all other users of the site.\nWe take a few minutes to look at the site and notice there are a lot of menu-item-names This is going to be a segment with a lot of rules. We quickly come up with an idea using R to scrape the site of all the menu-item-names and then create the segment using Adobe Analytics API v2.0.\nThe R packages, rvest and adobeanaltyicsr, can be used in tandem to help us win the day and be the heroes, delivering an efficient solution to the client.\nHere are the steps to get this done:"
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#first",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#first",
    "title": "Ben R Woodard's Blog",
    "section": "1. Authenticate And Load the Packages",
    "text": "1. Authenticate And Load the Packages\nThe client wants the products. Well you are familiar with the site enough to know that they have data attributes in the site elements. this should be enough of a start to get things going.\nAuthenticating just got better in the new version of the adobeanalyticsr package. Using the new JWT authentication process does not require you to login, like that of its brother authentication process, OAuth. This means you simply point the variables to the correct private.key file and you can start pulling data.\nStarting in adobeanaltyicsr v0.2.1 you can now use this function to authenticate.\n\naw_auth('jwt')"
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#second",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#second",
    "title": "Ben R Woodard's Blog",
    "section": "2. Scrape the site to gather the search terms.",
    "text": "2. Scrape the site to gather the search terms.\nIt doesn’t take long of getting into the digital analyst role before you realize clients are usually lacking in the data they want you to use. This made up client is no different. While they want you to use the list of menu-item-names, they don’t have a list of the terms yet. This means you are going ot have to figure out a way of collecting them.\nWe can use the rvest package to grab all the menu navigation links.\n\n#identify the URL\nurl &lt;- 'https://www.apple.com/'\n\n#scrape all the 'data-analytics-title' element attribute values\nsearchterms &lt;- rvest::read_html(url) %&gt;%\n  rvest::html_elements('ul li a') %&gt;%\n  rvest::html_attr('data-analytics-title') %&gt;%\n  na.omit()\n\nError in rvest::read_html(url) %&gt;% rvest::html_elements(\"ul li a\") %&gt;% : could not find function \"%&gt;%\"\n\n#25 of the 74 terms\nhead(searchterms, 25)\n\nError: object 'searchterms' not found\n\n\nWell that was pretty simple. There may be some minor cleanup but overall we have what we are needing to create the segment rules. There are 74 search terms we will need to use in our segment."
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#third",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#third",
    "title": "Ben R Woodard's Blog",
    "section": "3. Create the segment rules",
    "text": "3. Create the segment rules\nNow that we have the 74 search terms we needed we can get started on creating the segment. This will include any visits that have used any of these terms. Let’s make sure we have identified the key dimension that captures the search term used in searches on the site.\nFirst we need to pull the list of site dimensions using the aw_get_dimensions() function:\n\n#Pull the dimensions\ndims &lt;- aw_get_dimensions()\n\nOnce we have that list we need to narrow down the massive number of dimensions to the one we are looking for. We know that our dimension includes the word “search” in it so we do a quick filter function and pass a grepl as the argument value to select all dimension names that include the word ‘search’.\n\n#Filter the dimensions to find any that include the term \"search\"\nknitr::kable(dims %&gt;% \n  filter(grepl('search', name, ignore.case = T)) %&gt;%\n  select(id, name, description)\n)\n\nLooks like we can choose evar2 or prop2. Let’s go with evar2. Also, note that there is a “Search Keyword” dimension but we don’t want that because it is specific to Natural Search traffic.\nThis has been a cause for confusion and actually one of the reasons for this article. A co-worker created a 125 keyword list segment but instead of using the “Search Term” dimension he used the “Search Keyword” dimension. After discovering the error he had to go back and recreate the segment definition, recreating all 125 different rules.\nSo, now that we have identified evar2 as the appropriate dimension we want to setup our function to create all our rules or, as we will call them, predicates.\nAn adobe segment line item rule is really just a predicate. It contains a subject, linking verb, and predicate nominative. Our predicate nominative is the 74 menu-item-terms that we scraped from the site. We will use a map() function from the purrr package to apply each of the different keywords to the seg_rule() function which was introduced in version 0.3.0 of adobeanalyticsr.\nThe great part of the Adobe segment builder tool/API is that we can either collect all these into a comma delimited list along with the “eq-any-of” or “contains-any-of” verbs or we can create each rule separately. We are choosing here to create each one individually.\n\n#create the list of rules/predicates\nrules_list &lt;- purrr:::map(searchterms, function(x) {\n  adobeanalyticsr::seg_rule(dimension = 'evar2', \n                            verb = 'streq',\n                            object = x,\n                            validate = F) \n  })"
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#fourth",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#fourth",
    "title": "Ben R Woodard's Blog",
    "section": "4. Build the segment",
    "text": "4. Build the segment\nOnce we have the predicates built we can add them to the segment building function called seg_build. This function builds the JSON string needed for the API to then build a new segment.\nUsing the API forces us to be more intentional when creating a segment. We must include a name and description for each segment. Taking a little time to consider a good name and description for the segment will go a long way in using that segment in the intended reports and analyses of the future.\nWe also must include the context and conjunction. Remember that our client was asking about the ‘visits’ not ‘visitors’ or ‘hits’. In addition, they wanted to group any visit that included any of the terms. These two simple arguments are very important when considering what conclusions can be drawn from the data.\nFinally, we have the rules argument. This is a ‘list’ of rules that we created using the previous function.\nIf we create the segment in Adobe Analytics by using the argument create_seg=TRUE then the response will gives us the segment id which we will use in our future API calls.\n\n#build the segments with the list of predicates created\nres &lt;- adobeanalyticsr::seg_build(name = 'Apple Search Term Segment',\n                                  description = 'This segment includes a list of 74 search terms we want to see if users use as a search value',\n                                  context = 'visits',\n                                  conjunction = 'or',\n                                  rules = rules_list,\n                                  create_seg = FALSE)\n\n#\nseg_val(res)\n\nOnce completed we will have the final segment built and ready to be used.\n It’s hard for me to show the whole segment because it has 74 unique rules but this is a screenshot of the top 9 rules."
  },
  {
    "objectID": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#fifth",
    "href": "posts/2022-01-05-creating-huge-search-term-segments-in-minutes/index.html#fifth",
    "title": "Ben R Woodard's Blog",
    "section": "5. Grab some coffee",
    "text": "5. Grab some coffee\nWhile this is a made up story, it is based on a true example of how we have been able to use the Adobe Analytics API v2.0 to help cut development time and build efficiency into our workflows. In addition, using the API enables us to keep the naming conventions consistent across the different segments we create for a specific project.\nThere is still more development needed before the segment build function will be moved from the development version of adobeanalyticsr but if you have a segment building use case and would like some help in getting the solution, don’t hesitate to reach out!"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "Ben Woodard\n        \n                    November 16, 2025"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#setup",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#setup",
    "title": "Ben R Woodard's Blog",
    "section": "Setup",
    "text": "Setup\nI need to run a test that will have a good chance of getting results. How long should I run it for?\n\n# install.packages(\"rstanarm\")  # if needed\nlibrary(rstanarm)\n\nLoading required package: Rcpp\n\n\nThis is rstanarm version 2.32.2\n\n\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n\n\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n\n\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n\n\n  options(mc.cores = parallel::detectCores())\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.2\n✔ ggplot2   4.0.0     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# library(ggplot2)  # optional, for plotting\n\nset.seed(1234)"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#data-generator-simulate-an-ab-test-for-a-given-number-of-days",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#data-generator-simulate-an-ab-test-for-a-given-number-of-days",
    "title": "Ben R Woodard's Blog",
    "section": "2. Data generator: simulate an A/B test for a given number of days",
    "text": "2. Data generator: simulate an A/B test for a given number of days\nKey Terms:\n\nbaseline_p = control conversion rate\nlift = relative lift in treatment (e.g. 0.1 = +10% relative)\nvisitors_per_day = total visitors per day (split 50/50)\n\n\nsimulate_ab_binomial_days &lt;- function(\n  days,\n  visitors_per_day = 5000,\n  baseline_p       = 0.05,\n  lift             = 0.10   # 10% relative lift\n) {\n  days = 14\n  n_control_per_day  &lt;- floor(visitors_per_day / 2)\n  n_treat_per_day    &lt;- visitors_per_day - n_control_per_day\n  \n  n_control &lt;- n_control_per_day * days\n  n_treat   &lt;- n_treat_per_day   * days\n  \n  p_control &lt;- baseline_p\n  p_treat   &lt;- baseline_p * (1 + lift)\n  \n  y_control &lt;- rbinom(1, n_control, p_control)\n  y_treat   &lt;- rbinom(1, n_treat,   p_treat)\n  \n  data.frame(\n    group    = factor(c(\"Control\", \"Treatment\"),\n                      levels = c(\"Control\", \"Treatment\")),\n    successes = c(y_control, y_treat),\n    failures  = c(n_control - y_control,\n                  n_treat   - y_treat)\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#fit-bayesian-logistic-model-in-rstanarm",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#fit-bayesian-logistic-model-in-rstanarm",
    "title": "Ben R Woodard's Blog",
    "section": "3. Fit Bayesian logistic model in rstanarm",
    "text": "3. Fit Bayesian logistic model in rstanarm\nWe use a simple binomial regression: cbind(successes, failures) ~ group.\n\nfit_bayes_ab &lt;- function(dat,\n                         iter   = 1000,\n                         chains = 2) {\n  stan_glm(\n    cbind(successes, failures) ~ group,\n    data   = dat,\n    family = binomial(),\n    prior           = normal(0, 1, autoscale = TRUE),\n    prior_intercept = normal(0, 5, autoscale = TRUE),\n    chains = chains,\n    iter   = iter,\n    cores  = 1,   # keep it simple & robust\n    refresh = 0\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#bayesian-decision-rule-is-treatment-better",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#bayesian-decision-rule-is-treatment-better",
    "title": "Ben R Woodard's Blog",
    "section": "4. Bayesian decision rule: “Is treatment better?”",
    "text": "4. Bayesian decision rule: “Is treatment better?”\nWe use the posterior difference in conversion rates (not just the log-odds).\n\ncompute_decision &lt;- function(fit,\n                             prob_threshold = 0.95) {\n  nd &lt;- data.frame(\n    group = factor(c(\"Control\", \"Treatment\"),\n                   levels = c(\"Control\", \"Treatment\"))\n  )\n  \n  # Posterior predicted conversion rate for each group\n  pred &lt;- posterior_epred(fit,\n                            newdata  = nd)  # on probability scale\n  \n  # pred: draws x 2 (Control, Treatment)\n  diff_draws &lt;- pred[, 2] - pred[, 1]        # Treatment - Control\n  \n  post_prob &lt;- mean(diff_draws &gt; 0)          # P(Treatment &gt; Control)\n  list(\n    posterior_prob = post_prob,\n    success        = post_prob &gt;= prob_threshold\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#simulation-based-power-for-a-given-duration",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#simulation-based-power-for-a-given-duration",
    "title": "Ben R Woodard's Blog",
    "section": "5. Simulation-based “power” for a given duration",
    "text": "5. Simulation-based “power” for a given duration\nFor a given number of days, we:\nSimulate many fake tests.\nFit the Bayesian model each time.\nApply the decision rule.\nEstimate how often we’d “declare a win”.\nThat frequency is your Bayesian power for that duration.\n\nbayes_power_for_days &lt;- function(\n  days,\n  visitors_per_day = 5000,\n  baseline_p       = 0.05,\n  lift             = 0.10,\n  sims             = 100,    # bump up later (e.g. 500–1000)\n  prob_threshold   = 0.95,\n  iter             = 1000,\n  chains           = 2\n) {\n  results &lt;- map_dfr(1:sims, function(i) {\n    dat &lt;- simulate_ab_binomial_days(\n      days            = days,\n      visitors_per_day = visitors_per_day,\n      baseline_p      = baseline_p,\n      lift            = lift\n    )\n    \n    fit &lt;- fit_bayes_ab(dat, iter = iter, chains = chains)\n    dec &lt;- compute_decision(fit, prob_threshold = prob_threshold)\n    \n    tibble(\n      sim            = i,\n      posterior_prob = dec$posterior_prob,\n      success        = dec$success\n    )\n  })\n  \n  power_est &lt;- mean(results$success)\n  mean_prob &lt;- mean(results$posterior_prob)\n  \n  list(\n    days                = days,\n    power_estimate      = power_est,\n    mean_posterior_prob = mean_prob,\n    results             = results\n  )\n}"
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#estimate-required-duration-run-over-a-grid-of-days",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#estimate-required-duration-run-over-a-grid-of-days",
    "title": "Ben R Woodard's Blog",
    "section": "6. Estimate required duration: run over a grid of days",
    "text": "6. Estimate required duration: run over a grid of days\nNow we check, say, 7, 10, 14, 21, 28 days and see where power crosses your target (e.g. 0.8).\n\ndays_grid &lt;- c(7, 14, 21, 28)\n\npower_grid &lt;- map_dfr(days_grid, function(d) {\n  \n  res &lt;- bayes_power_for_days(\n    days             = d,\n    visitors_per_day = 5000,\n    baseline_p       = 0.05,\n    lift             = 0.10,   # 10% relative effect\n    sims             = 800,    # increase to 500+ for production\n    prob_threshold   = 0.95\n  )\n  \n  # Compute credible interval of the success indicator (power)\n  ci_lower &lt;- quantile(res$results$posterior_prob, 0.05)\n  ci_upper &lt;- quantile(res$results$posterior_prob, 0.95)\n  \n  tibble(\n    days                = d,\n    power_estimate      = res$power_estimate,\n    mean_prob           = mean(res$results$posterior_prob),\n    ci_lower            = ci_lower,\n    ci_upper            = ci_upper\n  )\n})\n\npower_grid\n\n# A tibble: 4 × 5\n   days power_estimate mean_prob ci_lower ci_upper\n  &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1     7          0.906     0.985    0.920        1\n2    14          0.904     0.980    0.897        1\n3    21          0.911     0.981    0.903        1\n4    28          0.912     0.981    0.904        1\n\n\nThen you’d say something like:\n“To detect a 10% lift with P(treatment &gt; control | data) ≥ 0.95 about 80–90% of the time, I need around 14–21 days at 5k visitors/day and 5% baseline.”\n\nggplot(power_grid, aes(x = days, y = power_estimate)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  geom_hline(yintercept = 0.8, linetype = \"dashed\", color = \"red\") +\n  scale_y_continuous(limits = c(0, 1), expand = c(0, 0)) +\n  labs(\n    title = \"Bayesian Power vs Test Duration\",\n    subtitle = \"With 90% credible intervals from simulation uncertainty\",\n    x = \"Test Length (days)\",\n    y = \"Bayesian Power (P(p_treat &gt; p_control) ≥ threshold)\"\n  ) +\n  theme_minimal(base_size = 14)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#conclusion",
    "href": "posts/2025-11-16-bayesian-power-analysis-in-r/index.html#conclusion",
    "title": "Ben R Woodard's Blog",
    "section": "Conclusion",
    "text": "Conclusion\nUsing a Bayesian approach to power analysis brings many more capabilities that the Frequentist approach does not. Some of these differences are more beneficial than others but overall, utilizing the Bayesian approach to power analysis is a great option.\n\n\n\n\n\n\n\n\nCapability\nFrequentist\nBayesian\n\n\n\n\nConnect power to an actual business decision\n❌\n✅\n\n\nIncorporate prior information\n❌\n✅\n\n\nUse a distribution of plausible effect sizes\n❌\n✅\n\n\nSimulate adaptive/sequential stopping\n❌ (hard)\n✅ (easy & valid)\n\n\nDirectly answer “probability treatment is better”\n❌\n✅\n\n\nModel realistic data-generating processes\nLimited\nExcellent\n\n\nHandle hierarchical/geo experiments\nHard\nNatural\n\n\nProvide interpretable outputs\n❌\n✅"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Ben R Woodard's Blog",
    "section": "",
    "text": "About\n          \n    \n                \n    \n  \n  \n    \n    \n  \n\n\nThat sun was really bright.\nBen has been working with clients in the digital marketing space for over 15 years. He got his start in analytics by developing Wordpress sites for clients which quickly led to implementing analytics solutions to track the value of the digital marketing dollars his clients were spending.\nIn 2008 he started his own digital analytics business managing website development projects, technical SEO audits, analytics implementation, and digital marketing analysis for over 50 different clients in a wide variety of industries.\nSince those early years, he has worked as a lead digital analyst in a rapidly growing non-profit, an analytics manager in a multi-billion dollar organization, and now as a Sr. Marketing Data Scientist.\nBen is based in the Athens, GA area with his wife, 3 boys, 2 dogs, a cat (who hates me), 10 ducks, 25 chickens, 2 turkeys, and 5 goats."
  }
]